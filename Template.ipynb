{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f20c1dd-18e0-4d8d-9f24-e3062e7d8fc5",
   "metadata": {},
   "source": [
    "## CLASSIFICATION LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50687390-a0d6-4d37-a305-ca2a6514f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,precision_score,recall_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "# Encoding Libraries\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from category_encoders import OrdinalEncoder, TargetEncoder\n",
    "\n",
    "\n",
    "\n",
    "#Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6387435-baad-4518-8bef-bb7cb71b0ed0",
   "metadata": {},
   "source": [
    "## REGRESSION LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aacc56-d5d5-46e5-9ca6-13a6abca8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Algorithms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Encoding Libraries\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from category_encoders import OrdinalEncoder, TargetEncoder\n",
    "\n",
    "\n",
    "#Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab67d2-6e24-48c8-b43e-80d78e91cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasist.structdata import detect_outliers\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler, LabelEncoder\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b8663b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement autoglucon (from versions: none)\n",
      "ERROR: No matching distribution found for autoglucon\n"
     ]
    }
   ],
   "source": [
    "!pip install autoglucon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826e2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45a6c3-d976-4c12-8561-9b035c20cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8511d-f415-4940-9495-ed87fc6bc604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values for categorical variables using fillna\n",
    "data['categorical_column'].fillna(value='unknown', inplace=True)\n",
    "\n",
    "# Filling missing values for numerical variables using fillna\n",
    "data['numerical_column'].fillna(value=data['numerical_column'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4352d647-4cb6-4e8d-a37c-148e0dd32dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filling missing values for categorical variables using SimpleImputer\n",
    "imputer_cat = SimpleImputer(strategy='constant', fill_value='unknown')\n",
    "data['categorical_column'] = imputer_cat.fit_transform(data[['categorical_column']])\n",
    "\n",
    "\n",
    "# Filling missing values for numerical variables using SimpleImputer\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "data['numerical_column'] = imputer_num.fit_transform(data[['numerical_column']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b65cc-b46e-4891-aa34-689a72c45f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scaling numerical features using MinMaxScaler\n",
    "scaler_minmax = MinMaxScaler()\n",
    "data[['numerical_column']] = scaler_minmax.fit_transform(data[['numerical_column']])\n",
    "\n",
    "# Scaling numerical features using StandardScaler\n",
    "scaler_standard = StandardScaler()\n",
    "data[['numerical_column']] = scaler_standard.fit_transform(data[['numerical_column']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451de839-89a8-4813-a884-ba6ff330feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering numerical columns\n",
    "numerical_columns = data.select_dtypes(include=['number']).columns\n",
    "numerical_data = data[numerical_columns]\n",
    "\n",
    "# Filtering categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n",
    "categorical_data = data[categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398240c1-1c16-49c2-b702-311d6d4a53eb",
   "metadata": {},
   "source": [
    "## PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ea6ba-1b89-482e-8547-ef0b08b13f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define preprocessing steps\n",
    "numeric_features = ['numeric_feature_1', 'numeric_feature_2']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['categorical_feature_1', 'categorical_feature_2']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "standard_scaler_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC())  # Example classifier, you can replace it with any other model\n",
    "])\n",
    "\n",
    "# Define the pipeline for MinMaxScaler\n",
    "minmax_scaler_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('svm', SVC())  # Example classifier, you can replace it with any other model\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Create pipeline with preprocessing and model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', RandomForestClassifier())])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Fit the pipeline on training data\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03801e17-2c07-4faa-a166-0d6a1f122d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1117957, 22)\n",
      "(745305, 21)\n"
     ]
    }
   ],
   "source": [
    "directory = r'C:\\Users\\ehina\\OneDrive\\Desktop\\Py-DS-ML-Bootcamp-master\\playground-series-s4e5\\\\'\n",
    "\n",
    "train = pd.read_csv(directory + 'train.csv')\n",
    "test = pd.read_csv(directory + 'test.csv')\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49729b3c-bd9b-4100-aeb6-0b201da4780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(train.isnull().sum()\n",
    "print(train.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e975a1a-fe1b-4b47-8df4-2e32b42f5dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train.select_dtypes(include='number').columns:\n",
    "    sns.histplot(train[column], kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()\n",
    "\n",
    "# Countplot for categorical variables\n",
    "for column in train.select_dtypes(include=['object', 'category']).columns:\n",
    "    sns.countplot(data=df, x=column)\n",
    "    plt.title(f'Countplot of {column}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2847a78-f671-4eb7-bac1-aca1ffda22a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)  # Output layer with one neuron for regression\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8725c205-5d56-4f16-9303-de5317cbe077",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513fd945-3e53-46c3-8ce2-6447457d3a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots(2,3)\n",
    "fig.set_figwidth(13)\n",
    "fig.set_figheight(8)\n",
    "ax2 = ax[0,0].twinx()\n",
    "ax3 = ax[0,2].twinx()\n",
    "\n",
    "sns.countplot(data=df,x=\"children\",ax=ax[0,0])\n",
    "sns.lineplot(data=df,x=\"children\",y=\"charges\",ax=ax3,color='r', marker='o',ci=None)\n",
    "sns.countplot(data=df,x=\"sex\",ax=ax[0,1],hue = 'smoker')\n",
    "sns.countplot(data=df,x=\"region\",ax=ax[0,2])\n",
    "sns.histplot(data=df,x=\"charges\",ax=ax[1,0],kde=True)\n",
    "sns.boxplot(data=df,y=\"charges\",x='smoker',ax=ax[1,1])\n",
    "sns.boxplot(data=df,y=\"charges\",ax=ax[1,2],x='sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db5355-3713-413d-a79d-4bbbf1b51a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
